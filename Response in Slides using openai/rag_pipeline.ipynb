{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Import necessary libraries\n",
    "import openai  # type: ignore\n",
    "import my_secrets\n",
    "import os\n",
    "import subprocess\n",
    "# import fitz  # PyMuPDF # type: ignore\n",
    "from sentence_transformers import SentenceTransformer  # type: ignore\n",
    "import faiss  # type: ignore\n",
    "import numpy as np  # type: ignore\n",
    "import chunks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Initialize embedding model and variables\n",
    "embedding_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "dimension = 384\n",
    "index = faiss.IndexFlatL2(dimension)\n",
    "embeddings = []\n",
    "image_dir = \"extracted_images\"\n",
    "os.makedirs(image_dir, exist_ok=True)\n",
    "MyChunks = chunks.Mychunks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Initialize embedding model and variables\n",
    "embedding_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "dimension = 384\n",
    "index = faiss.IndexFlatL2(dimension)\n",
    "embeddings = []\n",
    "image_dir = \"extracted_images\"\n",
    "os.makedirs(image_dir, exist_ok=True)\n",
    "MyChunks = chunks.Mychunks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Function to embed and index chunks\n",
    "def embed_and_index_chunks():\n",
    "    global embeddings\n",
    "    if embeddings:\n",
    "        print(\"Chunks already embedded and indexed.\")\n",
    "        return\n",
    "    for chunk in MyChunks:\n",
    "        text = chunk['text']\n",
    "        embedding = embedding_model.encode(text)\n",
    "        embeddings.append(embedding)\n",
    "        index.add(np.array([embedding]).astype(\"float32\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Function to retrieve relevant chunks based on query\n",
    "def retrieve_chunks(query, top_k=10):\n",
    "    query_embedding = embedding_model.encode(query)\n",
    "    distances, indices = index.search(\n",
    "        np.array([query_embedding]).astype(\"float32\"), top_k)\n",
    "    return [MyChunks[i] for i in indices[0]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Function to generate an answer from retrieved chunks\n",
    "def generate_answer(query, retrieved_chunks):\n",
    "    context = \"\\n\\n\".join(\n",
    "        [f\"Page {chunk['page']}: {chunk['text']}\" for chunk in retrieved_chunks])\n",
    "    return f\"Answer the question based on the following textbook content:\\n\\n{context}\\n\\nQuestion: {query}\\nAnswer:\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: Run the RAG pipeline\n",
    "def run_rag_pipeline(pdf_path, query):\n",
    "    if not MyChunks:\n",
    "        return \"No data available.\"\n",
    "    embed_and_index_chunks()\n",
    "    retrieved_chunks = retrieve_chunks(query)\n",
    "    return generate_answer(query, retrieved_chunks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: Load the OpenAI API key\n",
    "def load_openai_key():\n",
    "    return my_secrets.OPEN_AI_SECRET_KEY\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8: Function to call OpenAI's Chat API for LaTeX Beamer code generation\n",
    "def call_openai_chat(prompt, model=\"gpt-3.5-turbo\"):\n",
    "    openai.api_key = load_openai_key()\n",
    "    try:\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=model,\n",
    "            messages=[{\"role\": \"system\", \"content\": \"You are an expert in LaTeX and Beamer presentations.\"},\n",
    "                      {\"role\": \"user\", \"content\": prompt}],\n",
    "            max_tokens=4000,\n",
    "            temperature=0.7\n",
    "        )\n",
    "        return response['choices'][0]['message']['content'].strip()\n",
    "    except Exception as e:\n",
    "        return f\"An error occurred: {e}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 9: Save LaTeX code to a file\n",
    "def save_to_file(filename, content):\n",
    "    with open(filename, 'w') as f:\n",
    "        f.write(content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 10: Compile the LaTeX code into a PDF\n",
    "def compile_latex_to_pdf(tex_file):\n",
    "    try:\n",
    "        subprocess.run([\"pdflatex\", tex_file], check=True)\n",
    "        pdf_file = tex_file.replace('.tex', '.pdf')\n",
    "        return pdf_file if os.path.exists(pdf_file) else None\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"Error compiling LaTeX: {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 11: Extract valid LaTeX code from raw response\n",
    "def extract_latex_code(raw_response):\n",
    "    lines = raw_response.split(\"\\n\")\n",
    "    in_code_block = False\n",
    "    cleaned_lines = []\n",
    "    for line in lines:\n",
    "        if line.strip().startswith(\"```latex\"):\n",
    "            in_code_block = True\n",
    "            continue\n",
    "        if line.strip() == \"```\":\n",
    "            in_code_block = False\n",
    "            continue\n",
    "        if in_code_block:\n",
    "            cleaned_lines.append(line)\n",
    "    return \"\\n\".join(cleaned_lines)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PDF generated: response.pdf\n"
     ]
    }
   ],
   "source": [
    "# Cell 12: Main execution - Get user's prompt, process the document, generate LaTeX Beamer code, and compile into PDF\n",
    "\n",
    "# Step 1: Get the user's query\n",
    "user_prompt = input(\"Enter your prompt: \")\n",
    "\n",
    "# Step 2: Retrieve relevant chunks from the textbook\n",
    "pdf_path = \"Physics 9.pdf\"\n",
    "answer = run_rag_pipeline(pdf_path, user_prompt)\n",
    "\n",
    "# Step 3: Generate LaTeX Beamer code using OpenAI\n",
    "beamer_prompt = (\n",
    "    f\"Create a detailed LaTeX Beamer presentation on the following topic:\\n\\n\"\n",
    "    f\"{answer}\\n\\n\"\n",
    "    \"Include equations, bullet points, and TikZ-based diagrams to illustrate concepts. Use only TikZ to draw shapes or vectors \"\n",
    "    \"instead of relying on external image files. Ensure the output is ready-to-compile Beamer code.\"\n",
    ")\n",
    "raw_beamer_code = call_openai_chat(beamer_prompt)\n",
    "\n",
    "# Step 4: Extract valid LaTeX code\n",
    "beamer_code = extract_latex_code(raw_beamer_code)\n",
    "\n",
    "# Step 5: Save LaTeX code to a .tex file\n",
    "tex_filename = \"response.tex\"\n",
    "save_to_file(tex_filename, beamer_code)\n",
    "\n",
    "# Step 6: Compile the .tex file into a PDF\n",
    "pdf_filename = compile_latex_to_pdf(tex_filename)\n",
    "if pdf_filename:\n",
    "    print(f\"PDF generated: {pdf_filename}\")\n",
    "else:\n",
    "    print(\"Failed to generate PDF.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fyp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
