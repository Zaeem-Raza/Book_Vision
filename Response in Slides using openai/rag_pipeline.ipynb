{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>**Rag Pipeline**</center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Necessary Libraries\n",
    "\n",
    "In this cell, we import all the required libraries for the task. The libraries include:\n",
    "\n",
    "- `sentence_transformers`: A library for generating sentence embeddings (numerical representations) of text, which is used for comparing and retrieving chunks of text.\n",
    "- `faiss`: A library for efficient similarity search and clustering of dense vectors, which helps in finding the most relevant chunks of text based on a query.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import openai  \n",
    "import my_secrets\n",
    "import os\n",
    "import subprocess\n",
    "from sentence_transformers import SentenceTransformer  \n",
    "import faiss  \n",
    "import numpy as np  \n",
    "import chunks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initializing Sentence Embeddings, FAISS Index, and Setting Up Directories\n",
    "\n",
    "In this cell, we perform several key initializations for embedding and indexing text chunks from a PDF document:\n",
    "\n",
    "1. **Loading Sentence Transformer Model**:\n",
    "\n",
    "   - We use the `SentenceTransformer` model `all-MiniLM-L6-v2` to generate sentence embeddings. This model is pre-trained to create dense vector representations (embeddings) of text, which can be used for tasks like similarity search and clustering.\n",
    "\n",
    "2. **Setting Embedding Dimension**:\n",
    "\n",
    "   - The `dimension` is set to 384, which corresponds to the number of features in the embeddings generated by the `all-MiniLM-L6-v2` model. This is the fixed size of the vector representations.\n",
    "\n",
    "3. **Creating FAISS Index**:\n",
    "   - FAISS (Facebook AI Similarity Search) is used to efficiently search through the embeddings. We initialize a `IndexFlatL2` index, which will store the embeddings in a way that allows us to quickly compute similarity searches (in this case, using L2 distance).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "dimension = 384\n",
    "index = faiss.IndexFlatL2(dimension)\n",
    "embeddings = []\n",
    "image_dir = \"extracted_images\"\n",
    "os.makedirs(image_dir, exist_ok=True)\n",
    "MyChunks = chunks.Mychunks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding and Indexing Chunks\n",
    "\n",
    "1. **Embedding Text from Chunks**:\n",
    "\n",
    "   - If the embeddings are not yet created, the function loops through each chunk in the `MyChunks` collection.\n",
    "   - For each chunk, it extracts the `text` field and passes it to the `embedding_model.encode()` method, which generates an embedding (a vector representation) of the text. This embedding is then appended to the `embeddings` list.\n",
    "\n",
    "2. **Indexing the Embeddings**:\n",
    "   - Each embedding is added to the FAISS index using the `index.add()` method. Since FAISS requires the embeddings to be in the form of `float32` arrays, the code converts the embedding to the appropriate format using `np.array([embedding]).astype(\"float32\")`.\n",
    "     .\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_and_index_chunks():\n",
    "    global embeddings\n",
    "    if embeddings:\n",
    "        print(\"Chunks already embedded and indexed.\")\n",
    "        return\n",
    "    for chunk in MyChunks:\n",
    "        text = chunk['text']\n",
    "        embedding = embedding_model.encode(text)\n",
    "        embeddings.append(embedding)\n",
    "        index.add(np.array([embedding]).astype(\"float32\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieving Relevant Chunks Based on Query\n",
    "\n",
    "1. **Generating Query Embedding**:\n",
    "\n",
    "   - The input `query` (a string) is passed to the `embedding_model.encode()` method to generate an embedding (numerical representation) for the query.\n",
    "\n",
    "2. **Searching for Closest Chunks**:\n",
    "\n",
    "   - The generated query embedding is then passed to the FAISS index using the `index.search()` method. This performs a search to find the nearest vectors (embeddings) to the query embedding.\n",
    "   - The `top_k` parameter determines how many closest results (chunks) will be retrieved. By default, it retrieves the top 10 most relevant chunks.\n",
    "\n",
    "3. **Returning Relevant Chunks**:\n",
    "   - The `indices` returned by FAISS are used to select the corresponding chunks from the `MyChunks` list. The function returns these top `k` chunks that are most similar to the query.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_chunks(query, top_k=10):\n",
    "    query_embedding = embedding_model.encode(query)\n",
    "    distances, indices = index.search(\n",
    "        np.array([query_embedding]).astype(\"float32\"), top_k)\n",
    "    return [MyChunks[i] for i in indices[0]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating Answer Based on Retrieved Chunks\n",
    "\n",
    "In this cell, the function `generate_answer(query, retrieved_chunks)` is responsible for generating a structured prompt that can be used to answer a user's question based on the content of the retrieved chunks. Here's how it works:\n",
    "\n",
    "1. **Creating the Context**:\n",
    "\n",
    "   - The function begins by creating a context string that consists of the relevant chunks retrieved from the previous step. Each chunk is formatted to display the page number and the corresponding text.\n",
    "   - The chunks are joined together with two newlines (`\\n\\n`) for better readability.\n",
    "\n",
    "2. **Answer Generation Prompt**:\n",
    "   - The function constructs a final prompt that includes:\n",
    "     - The context made up of relevant chunks.\n",
    "     - The user's query, which is passed as the input `query` parameter.\n",
    "   - This prompt is designed to instruct a language model (e.g., OpenAI) to generate an answer based on the provided context.\n",
    "\n",
    "The generated prompt is returned as a structured string, which will be used in subsequent steps to call a language model (like OpenAI's GPT) to generate an answer based on the content of the textbook.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_answer(query, retrieved_chunks):\n",
    "    context = \"\\n\\n\".join(\n",
    "        [f\"Page {chunk['page']}: {chunk['text']}\" for chunk in retrieved_chunks])\n",
    "    return f\"Answer the question based on the following textbook content:\\n\\n{context}\\n\\nQuestion: {query}\\nAnswer:\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running the RAG Pipeline\n",
    "\n",
    "In this cell, we define the function `run_rag_pipeline(pdf_path, query)` to execute the full process of retrieving relevant content from the PDF and generating an answer to a user's query. The function performs the following steps:\n",
    "\n",
    "1. **Check for Available Chunks**:\n",
    "\n",
    "   - First, the function checks if there are any chunks in `MyChunks`. If there are no chunks, it returns the message `\"No data available.\"`. This ensures that the pipeline doesn't run unless there is data to process.\n",
    "\n",
    "2. **Embedding and Indexing**:\n",
    "\n",
    "   - If chunks are available, it calls `embed_and_index_chunks()` to generate embeddings for each chunk and index them using FAISS. This prepares the chunks for efficient retrieval.\n",
    "\n",
    "3. **Retrieve Relevant Chunks**:\n",
    "\n",
    "   - It then calls `retrieve_chunks(query)` to fetch the most relevant chunks based on the user's query. The function uses the embeddings and FAISS indexing to perform this retrieval efficiently.\n",
    "\n",
    "4. **Generate Answer**:\n",
    "   - Finally, it calls `generate_answer(query, retrieved_chunks)` to generate a detailed response to the user's query, using the relevant chunks as context.\n",
    "\n",
    "The final output of the function is the generated answer based on the queried content from the PDF.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_rag_pipeline(pdf_path, query):\n",
    "    if not MyChunks:\n",
    "        return \"No data available.\"\n",
    "    embed_and_index_chunks()\n",
    "    retrieved_chunks = retrieve_chunks(query)\n",
    "    return generate_answer(query, retrieved_chunks)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Loading the OpenAI API Key\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_openai_key():\n",
    "    return my_secrets.OPEN_AI_SECRET_KEY\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_openai_chat(prompt, model=\"gpt-3.5-turbo\"):\n",
    "    openai.api_key = load_openai_key()\n",
    "    try:\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=model,\n",
    "            messages=[{\"role\": \"system\", \"content\": \"You are an expert in LaTeX and Beamer presentations.\"},\n",
    "                      {\"role\": \"user\", \"content\": prompt}],\n",
    "            max_tokens=4000,\n",
    "            temperature=0.7\n",
    "        )\n",
    "        return response['choices'][0]['message']['content'].strip()\n",
    "    except Exception as e:\n",
    "        return f\"An error occurred: {e}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_to_file(filename, content):\n",
    "    with open(filename, 'w') as f:\n",
    "        f.write(content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Compiling LaTeX Code into a PDF`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile_latex_to_pdf(tex_file):\n",
    "    try:\n",
    "        subprocess.run([\"pdflatex\", tex_file], check=True)\n",
    "        pdf_file = tex_file.replace('.tex', '.pdf')\n",
    "        return pdf_file if os.path.exists(pdf_file) else None\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"Error compiling LaTeX: {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Extracting Valid LaTeX Code from Raw Response`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_latex_code(raw_response):\n",
    "    lines = raw_response.split(\"\\n\")\n",
    "    in_code_block = False\n",
    "    cleaned_lines = []\n",
    "    for line in lines:\n",
    "        if line.strip().startswith(\"```latex\"):\n",
    "            in_code_block = True\n",
    "            continue\n",
    "        if line.strip() == \"```\":\n",
    "            in_code_block = False\n",
    "            continue\n",
    "        if in_code_block:\n",
    "            cleaned_lines.append(line)\n",
    "    return \"\\n\".join(cleaned_lines)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main Execution: Get User's Prompt, Process the Document, Generate LaTeX Beamer Code, and Compile into PDF\n",
    "\n",
    "This cell runs the complete process starting from getting the user's query, retrieving relevant chunks of text, generating LaTeX Beamer code, and compiling it into a PDF.\n",
    "\n",
    "- **Step 1: Get the user's query**\n",
    "\n",
    "- **Step 2: Retrieve relevant chunks from the textbook**\n",
    "\n",
    "- **Step 3: Generate LaTeX Beamer code using OpenAI**\n",
    "\n",
    "- **Step 4: Extract valid LaTeX code**\n",
    "\n",
    "- **Step 5: Save LaTeX code to a .tex file**\n",
    "\n",
    "- **Step 6: Compile the .tex file into a PDF**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer the question based on the following textbook content:\n",
      "\n",
      "Page 58: moving then difficult to stop. Newton concluded that everybody resists to the change in its state of rest or of uniform motion in a straight line. He called this property of matter as inertia. He related the inertia of a body with its mass; greater is the mass of a body greater is its inertia. Inertia of a body is its property due to which it resists any change in its state of rest or motion. Let us perform an experiment to understand inertia. EXPERIMENT 3.1 Take a glass and cover it with a piece of cardboard. Place a coin\n",
      "\n",
      "Page 45: Unit 2: Kinematics Physics IX\n",
      "\n",
      "Page 191: Physics IX 191\n",
      "\n",
      "Page 51: 51 Unit 2: Kinematics Physics IX SUMMARY A body is said to be at rest, if it does not change its position with respect to its surroundings. A body is said to be in motion, if it changes its position with respect to its surroundings. Rest and motion are always relative. There is no such thing as absolute rest or absolute motion. Motion can be divided into the following three types. � Translatory motion: In which a body moves without any rotation. � Rotatory motion: In which a body spins about its axis. � Vibratory motion: In which a body\n",
      "\n",
      "Page 77: Earth is circular motion. The motion of an object in a circular path is known as circular motion. CENTRIPETAL FORCE Consider a body tied at the end of a string moving with uniform speed in a circular path. A body has the tendency to move in a straight line due to inertia. Then why does the body move in a circle? The string to which the body is tied keeps it to move in a circle by pulling the body towards the centre of the circle. The string pulls the body perpendicular to its motion as shown in figure 3.26.\n",
      "\n",
      "Page 78: Centripetal force Centrifugal force Unit 3: Dynamics Physics IX 78 moves away along a tangent to the circle as shown in figure 3.27(b). (ii) The moon revolves around the Earth. The gravitational force of the Earth provides the necessary centripetal force. Let a body of mass m moves with uniform speed v in a circle of radius r. The acceleration a produced by the c centripetal force F is given by c centripetal acceleration According to Newton's second law of motion, the centripetal force F is given by c Equation (3.26) shows that the centripetal force needed by a body\n",
      "\n",
      "Page 57: Unit 3: Dynamics Physics IX 58 between moving parts of industrial machines and on wheels spinning on axles). identify the use of centripetal force in (i) safe driving by banking roads (ii) washing machine dryer (iii) cream separator. In kinematics, we have studied the changes in motion only. Our understanding about the changes in motion is of little value without knowing its causes. The branch of mechanics that deals with the study of motion of an object and the cause of its motion is called dynamics. In this unit, we shall study momentum and investigate what causes a change in\n",
      "\n",
      "Page 82: Unit 3: Dynamics Physics IX 82 (c) decreases when moving with high velocity (d) none of the above. vi. Two bodies of masses m and m 1 2 attached to the ends of an inextensible string passing over a frictionless pulling such that both move vertically. The acceleration of the bodies is: vii. Which of the following is the unit of momentum? -2 (a) Nm (b) kgms -1 (c) Ns (d) Ns viii. When horse pulls a cart, the action is on the: (a) cart (b) Earth � horse (d) Earth and cart ix. Which of the following material lowers\n",
      "\n",
      "Page 29: 29 Unit 2: Kinematics Physics IX 2.1 REST AND MOTION We see various things around us. Some of them are at rest while others are in motion. The state of rest or motion of a body is relative. For example, a passenger sitting in a moving bus is at rest because he/she is not changing his/her position with respect to other passengers or objects in the bus. But to an observer outside the bus, the passengers and the objects inside the bus are in motion. 2.2 TYPES OF MOTION If we observe carefully, we will find that everything in the\n",
      "\n",
      "Page 80: a body.  Inertia of a body is its property due to which it resists any change in its state of rest or uniform motion in a straight line.  Momentum of a body is the quantity of motion possessed by the body. Momentum of a body is equal to the product of its mass and velocity  The force that opposes the motion of a body is called friction.  Newton's first law of motion states that a body continues its state of rest or of uniform motion in a straight line provided no net force acts on it.\n",
      "\n",
      "Question: ehat is inertia\n",
      "Answer:\n"
     ]
    }
   ],
   "source": [
    "user_prompt = input(\"Enter your prompt: \")\n",
    "\n",
    "pdf_path = \"Physics 9.pdf\"\n",
    "answer = run_rag_pipeline(pdf_path, user_prompt)\n",
    "\n",
    "print(answer)\n",
    "\n",
    "\n",
    "# beamer_prompt = (\n",
    "#     f\"Create a detailed LaTeX Beamer presentation on the following topic:\\n\\n\"\n",
    "#     f\"{answer}\\n\\n\"\n",
    "#     \"Include equations, bullet points, and TikZ-based diagrams to illustrate concepts. Use only TikZ to draw shapes or vectors \"\n",
    "#     \"instead of relying on external image files. Ensure the output is ready-to-compile Beamer code.\"\n",
    "# )\n",
    "# raw_beamer_code = call_openai_chat(beamer_prompt)\n",
    "\n",
    "# beamer_code = extract_latex_code(raw_beamer_code)\n",
    "\n",
    "# tex_filename = \"response.tex\"\n",
    "# save_to_file(tex_filename, beamer_code)\n",
    "\n",
    "# pdf_filename = compile_latex_to_pdf(tex_filename)\n",
    "# if pdf_filename:\n",
    "#     print(f\"PDF generated: {pdf_filename}\")\n",
    "# else:\n",
    "#     print(\"Failed to generate PDF.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fyp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
